{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f6e38fc-9f24-4c8f-9e2e-2c120eb68d45",
   "metadata": {},
   "source": [
    "# Unlocking the Power of Intelligent Document Processing with Amazon Textract and Amazon Bedrock\n",
    "---\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> \n",
    "    <b>NOTE:</b> You will need to use a Jupyter Kernel with Python 3.9 or above to use this notebook. If you are in Amazon SageMaker Studio, you can use the `Data Science 3.0` image.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"> \n",
    "    <b>NOTE:</b> You will need 3rd party model access to Anthropic Claude 3 Sonnet and Haiku models to be able to run this notebook. Verify if you have access to the model by going to <a href=\"https://console.aws.amazon.com/bedrock\" target=\"_blank\">Amazon Bedrock console</a> > left menu \"Model access\". The \"Access status\" for Anthropic Claude must be in \"Access granted\" status in green. If you do not have access, then click \"Edit\" button on the top right > select the model checkbox > click \"Save changes\" button at the bottom. You should have access to the model within a few moments.\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "---------------\n",
    "In this notebook, we will explore the powerful capabilities of Amazon Textract and Amazon Bedrock for intelligent document processing (IDP). IDP involves automatically extracting valuable information from documents, enabling organizations to streamline document-centric workflows, reduce operational costs, and gain insights from their data.\n",
    "\n",
    "Amazon Textract uses advanced machine learning and computer vision technologies to accurately extract text, data, and metadata from various document formats, including PDFs, images, and scanned documents. By automating this process, Textract eliminates the need for manual data entry, increasing efficiency and reducing the risk of errors.\n",
    "\n",
    "Amazon Bedrock, on the other hand, provides access to state-of-the-art large language models (LLMs) that can understand and process both text and visual data. These multi-modal models can accurately identify and extract relevant information from structured, semi-structured, and unstructured documents, enabling tasks such as form extraction, table extraction, and intelligent question answering.\n",
    "\n",
    "Together, Textract and Bedrock form a powerful combination for building intelligent document processing pipelines. Textract handles the initial document ingestion and text extraction, while Bedrock's LLMs provide advanced understanding and extraction capabilities.\n",
    "\n",
    "Throughout this notebook, we will explore the key features of both services and learn how to integrate them into your workflows using Python libraries like Textractor and Rhubarb. By the end of this notebook, you will have a solid understanding of how to leverage AWS for efficient and accurate document processing, enabling your organization to unlock valuable insights from its data assets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8d9e90",
   "metadata": {},
   "source": [
    "## Basic building blocks\n",
    "---\n",
    "This lab is an introduction to the libraries and interfaces used in subsequent intelligent document processing with generative AI labs. It introduces the key libraries that will be used, along with providing code samples that you can modify in your own workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3b0ee4-b856-4718-992e-99390f56068e",
   "metadata": {},
   "source": [
    "### Setup Prerequisites\n",
    "---\n",
    "\n",
    "First we need to \n",
    "1. Install Textractor. This open source python library makes it easy to parse and handle the JSON output from Amazon Textract\n",
    "1. Install Rhubarb. This open source python ligrary makes it easy to use Amazon Bedrock multimodal capibiliteis for IDP\n",
    "1. Install Sagemaker to give you access to a Sagemaker session context. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c12c62-2259-48b9-8148-70a540c28ae5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python -m pip install \"amazon-textract-textractor[pdf]\"\n",
    "!python -m pip install pyrhubarb\n",
    "!python -m pip install sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bd886e-d953-4b0e-81a1-54d72847b8f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Import script libraries and create global variables\n",
    "import json\n",
    "import sagemaker\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "data_bucket = sagemaker.Session().default_bucket()\n",
    "region = sagemaker.Session().boto_region_name\n",
    "print(f\"SageMaker bucket is {data_bucket}, and SageMaker Execution Role is {role}. Current region is {region}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f216317d",
   "metadata": {},
   "source": [
    "### Use Boto3 to call the Bedrock API\n",
    "---\n",
    "Sending a prompt directly to Bedrock with Boto3 is easy and gives fine grain control over your prompt and parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bc12a4-44de-4352-84b9-3218813fe731",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "bedrock = boto3.client(service_name=\"bedrock-runtime\", region_name=region)\n",
    "\n",
    "#Create a global function to call Bedrock. \n",
    "def get_response_from_claude(prompt, temp=1, model='sonnet'):\n",
    "\t\"\"\"\n",
    "\tInvokes Anthropic Claude 3 Haiku to run a text inference using the input\n",
    "\tprovided in the request body.\n",
    "\n",
    "\t:param prompt:  The prompt that you want Claude 3 to use.\n",
    "\t:param temp:    The temperature to use when invoking Claude. Default is 1\n",
    "\t:param model:   The claude model to use. Currently this supports haiku and sonnet. Default is Sonnett\n",
    "\t:return:        Text response, input token count, output token count\n",
    "\t\"\"\"\n",
    "\n",
    "\t# Invoke the model with the prompt and the encoded image\n",
    "\tmodel_dict = {\n",
    "        \"haiku\":\"anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "        \"sonnet\":\"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "    }\n",
    "\tmodel_id = model_dict[model]\n",
    "\trequest_body = {\n",
    "\t\t\"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "\t\t\"max_tokens\": 4096,\n",
    "        \"temperature\":temp,\n",
    "\t\t\"messages\": [\n",
    "\t\t\t{\n",
    "\t\t\t\t\"role\": \"user\",\n",
    "\t\t\t\t\"content\": [\n",
    "\t\t\t\t\t{\n",
    "\t\t\t\t\t\t\"type\": \"text\",\n",
    "\t\t\t\t\t\t\"text\": prompt,\n",
    "\t\t\t\t\t},\n",
    "\t\t\t\t],\n",
    "\t\t\t}\n",
    "\t\t],\n",
    "\t}\n",
    "\n",
    "\ttry:\n",
    "\t\tresponse = bedrock.invoke_model(\n",
    "\t\t\tmodelId=model_id,\n",
    "\t\t\tbody=json.dumps(request_body),\n",
    "\t\t)\n",
    "\n",
    "\t\t# Process and print the response\n",
    "\t\tresult = json.loads(response.get(\"body\").read())\n",
    "\t\tinput_tokens = result[\"usage\"][\"input_tokens\"]\n",
    "\t\toutput_tokens = result[\"usage\"][\"output_tokens\"]\n",
    "\n",
    "\t\t# the current Bedrock Claude Messagees API only supports text content in responses\n",
    "\t\ttext_response = result[\"content\"][0][\"text\"]\n",
    "\n",
    "        # return a tuple with 3 values\n",
    "\t\treturn text_response, input_tokens, output_tokens\n",
    "\texcept ClientError as err:\n",
    "\t\tprint(\n",
    "\t\t\tF\"Couldn't invoke Claude 3 Sonnet. Here's why: {err.response['Error']['Code']}: {err.response['Error']['Message']}\"\n",
    "\t\t)\n",
    "\t\traise\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1585e7-0776-4482-b89d-78f348504925",
   "metadata": {},
   "source": [
    "### 1. Basic usage with Amazon Textract and Amazon Textractor\n",
    "---\n",
    "This code block demonstrates how to use the Amazon Textract service directly through the AWS SDK for Python (Boto3) to extract text from a document stored in an Amazon S3 bucket. It first uploads the document to S3, then calls the `detect_document_text` method of the Textract client to perform text detection on the document. The response from Textract is then parsed using the `textractor.parsers.response_parser` module to create a more user-friendly representation of the detected text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9093a6-ce0f-481e-8d82-14a07a860191",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from textractor.parsers import response_parser\n",
    "\n",
    "textract = boto3.client('textract')\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "# first we upload the file to S3\n",
    "s3.upload_file(Filename='../samples/discharge-summary.png', Bucket=data_bucket, Key='samples/discharge-summary.png')\n",
    "\n",
    "# next We will use the Textract detect document text action to get all the text in the document.\n",
    "textract_response = textract.detect_document_text(\n",
    "    Document={'S3Object': \n",
    "              {'Bucket': data_bucket,'Name': 'samples/discharge-summary.png'}\n",
    "             }, \n",
    "\t)\n",
    "\t\n",
    "# Textractor provides a parser to give us a summary of the contents and a string with the detected text\n",
    "document = response_parser.parse(textract_response)\n",
    "\n",
    "# the document object contains a summary of what textract returned \n",
    "print(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f2345a",
   "metadata": {},
   "source": [
    "### Using the Textractor library\n",
    "---\n",
    "This library provides a higher-level interface for working with Amazon Textract. Instead of calling Textract directly, you can use Textractor's caller methods[caller methods](https://aws-samples.github.io/amazon-textract-textractor/textractor.html) method, which abstracts away some of the complexities of interacting with the Textract service. In this example, Textractor is used to extract text from a document stored in an S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdf8eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textractor import Textractor\n",
    "extractor = Textractor(region_name=region)\n",
    "\n",
    "document = extractor.detect_document_text('s3://' + data_bucket + '/samples/discharge-summary.png')\n",
    "print(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20f448d",
   "metadata": {},
   "source": [
    "---\n",
    "You can also use Textractor to extract text from a local file on your machine, rather than a file stored in S3. This can be more convenient for smaller projects or local testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0ed3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textractor import Textractor\n",
    "extractor = Textractor(region_name=region)\n",
    "\n",
    "document = extractor.detect_document_text(\"../samples/discharge-summary.png\")\n",
    "print(document.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b3b9dc",
   "metadata": {},
   "source": [
    "---\n",
    "Textractor also works with Textract's asynchronous methods, which are useful for processing multi-page documents. It first uploads a PDF file to S3, then calls Textractor's `start_document_text_detection` method to initiate an asynchronous text detection job. The results of this job are then printed out page by page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85acfec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textractor import Textractor\n",
    "extractor = Textractor(region_name=region)\n",
    "\n",
    "# first we upload the file to S3\n",
    "s3.upload_file(Filename='../samples/employee_enrollment.pdf', Bucket=data_bucket, Key='samples/employee_enrollment.pdf')\n",
    "\n",
    "document = extractor.start_document_text_detection(file_source=\"s3://\" + data_bucket + \"/samples/employee_enrollment.pdf\",\n",
    "    save_image=False)\n",
    "\n",
    "for page in document.pages:\n",
    "    print(page)\n",
    "    print(\"\\n----------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed904147-9ed1-4db1-81ee-5a433624b204",
   "metadata": {},
   "source": [
    "---\n",
    "You can retrieve the full text content of the document from the Textractor `document` object, which can then be used as input for a Retrieval-Augmented Generation (RAG) model implemented using the Bedrock library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9578d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f\"\\nDetected Text \\n=========================\\n\")\n",
    "doc_text = document.get_text()\n",
    "print(doc_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb476c1",
   "metadata": {},
   "source": [
    "### 2. Basic usage with Bedrock\n",
    "---\n",
    "Now we can use the Bedrock library to generate a response based on the document text extracted by Textractor. It constructs a prompt that includes the document text, and then calls a previously defined function `get_response_from_claude` to generate a response based on that prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67334979",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "\n",
    "Given the document\n",
    "\n",
    "<document>{doc_text}<document>\n",
    "\n",
    "What is the employee's name?\n",
    "\"\"\"\n",
    "\n",
    "response = get_response_from_claude(prompt)\n",
    "\n",
    "print (f\"Our prompt has {response[1]} input tokens and Claude returned {response[2]} output tokens \\n\\n=========================\\n\")\n",
    "print(response[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd3649a",
   "metadata": {},
   "source": [
    "### 3. Basic usage with Rhubarb\n",
    "---\n",
    "\n",
    "The Rhubarb library, which provides a high-level interface for using Bedrock's multi-modal models (models that can process both text and images/documents). It demonstrates how to create a `DocAnalysis` object with a local PDF file, and then use that object to generate a response to a textual query using one of Bedrock's multi-modal models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fb4152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "session = boto3.Session()\n",
    "from rhubarb import DocAnalysis\n",
    "\n",
    "da = DocAnalysis(file_path=\"../samples/employee_enrollment.pdf\", boto3_session=session)\n",
    "resp = da.run(message=\"What is the employee's name?\")\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497cb636-9ea2-4f3f-aa6e-a856574a2a17",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "---\n",
    "Let's delete the sample files we uploaded earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc2d322-c0b9-4eec-b544-edf6d761b15b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3.delete_object(Bucket=data_bucket, Key='samples/discharge-summary.png')\n",
    "s3.delete_object(Bucket=data_bucket, Key='samples/employee_enrollment.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969fbd21-e126-4bde-9907-29d30ec0c9bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
